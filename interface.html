<link rel="stylesheet" href="css/reset.css"/>
<link rel="stylesheet" href="css/interface.css">

<p>Visual interfaces mediate a user and their goals. Interacting with an interface triggers another action; clicking an icon opens a file, for example. What is not always immediately obvious to the user, however, are the activities occurring beneath the surface.  As such, interfaces are inherently a representation or abstraction of some other process. Clicking the “Place your order” button on the Amazon checkout page triggers a flurry of activities: money is exchanged, a warehouse employee has a new order to fulfill, a shipping label is printed, your suggestions algorithm is updated. All the consumer notices is an email notification, a line on their bank statement, and a package a few days later. By choosing to expose or conceal certain processes, designers wield considerable influence and control over a user’s perception. There is an information asymmetry between user and service provider that is arguably insufficiently addressed by current design practices. </p>
<p>Digital products have immense power in their efficiency and flexibility. Instead of going into a bank to inquire about one’s balance, mobile banking provides up to the minute updates on one’s expenses. Paperwork can be reduced to a few forms, spreadsheets, and databases, but there is still some physical act or object that accompanies the digital. The immediate convenience of tapping a button to get a ride is hard to deny, but what is significantly less obvious is the impact on local transit systems and working wages. Everything that exists and happens in the digital world has some effect in the physical world. The ease and convenience of digital often betrays the complex underlying systems and infrastructures that support it. That isn’t to say that on-demand ridesharing shouldn’t exist or getting a ride ought to be a difficult and inconvenient task, but, rather, designers should be asking not only how to create a pleasant and streamlined experience but also how to encourage users to critically evaluate their actions and choices. <h1>How can critical thought be integrated into a seamless experience?</h1>It is necessary to understand and question what is communicated to the end user. Admittedly, to ask users to contemplate systems and understand their own role within them is a lot, but if individuals are never given the oppurtunity to see and understand underlying processes, it is nearly impossible for them to critically evaluate it. Individuals should not be simply thought of as users but as actors with agency. </p>
<p>Usability and efficiency are generally the standard parameters for evaluating digital products and experiences. Different methods for measuring and quantifying usability exist, but none begin to address transparency. Transparency, especially in the context of governance, is generally understood to be about openness– the ability to see all decisions being made. In the context of design, transparency refers to the clarity of communication between user and provider. What does the provider know that the consumer does not? What does the consumer understand about the provider? If there is an information imbalance, can the relationship become more balanced? Design should, by default, be questioning relationships, as Matt Wade explains. Why does a particular consumer/ provider relationship exist in its current form? Can it be modified? If the system a problem is born out of is not challenged, it is very likely the solution will only continue contributing to the system. (Dunne, Raby)(user/service provider relationship diagram)</p>
<p>Absolute transparency is not necessarily the answer, but designers need to consider what is or is not exposed to the end user and the justification behind such decisions. A button does not just lead to another screen. Data is captured, information is exchanged, a series of other actions are set into motion, often unbeknownst to the user. What actions can users take on a particular screen? What happens when they interact with said screen? What do they see or not see?</p>
<p>There are plenty of visualization techniques, such as service blueprints and user flows, that begin to answer these questions surrounding visible touchpoints, but they mostly enable the designer to analyze and optimize each interaction. They do not adequately address the transparency of interactions and relationships. In order to design for transparency, it may be helpful to use the association map pictured  below. Focusing on invisible versus visible and abstract versus literal orients the product and gives the designer a space to begin questioning. Whether used by the designer or the consumer, visualizing where the product sits on the coordinate plane allows for insights into the transparency of a design.</p>
<p>The value of considering whether a product is invisible or visible to evaluate transparency is fairly straightforward; if something can be seen by consumers, they can react accordingly. Depending on the context, the designer may want some processes to be visible, others to be invisible. Seeing hotel staff deliver fresh dry cleaning is  indicative of a luxurious experience, but guests might not be as enchanted by seeing the actual dry cleaning process done somewhere in a factory. One way to think about creating visibility and transparency is through intentionally designing glitches. Jonathan Hanahan writes, “The designer should no longer be required to hide and destroy glitches, but design them outright, crafting intentional disruptions to experiences as means to reveal and understand their ramifications.” The glitch is a moment of hypervisibility where the previously invisible is pushed to the forefront, encouraging the participant to reevaluate their experience. For example, in the case of online shopping, in the U.S., Amazon is the go to e-commerce site for many because of convenience, speed, and price. In addition to Amazon, third party sellers are able to sell their wares on the platform, but the buyer never leaves the Amazon ecosystem; even though the order is fulfilled by a the third party, from the buyer's point of view, it's a seamless Amazon experience. However, one particular purchase from a third party seller stood out because of a glitch in an otherwise seamless experience. Housing Works is a nonprofit based in New York City whose model includes selling used books on the Amazon platform to fund Housing Work’s efforts in providing services to those living with and affected by HIV and AIDS. Slipped in the books sold is a bookmark, explaining the organization’s mission. The bookmark is a glitch disrupting the typical Amazon purchasing experience while leaving the core experience intact; the consumer is reminded that they are not purchasing a book from Amazon but from Housing Works. Knowing that their dollars are funding a charitable cause, consumers may shift their buying practices.</p>
<p>However, visibility alone is an insufficient parameter, as visibility and comprehension are not necessarily equivalent. Terms of service agreements, for example, are visible to the user. However, they are not always comprehensible. Asking whether a design is literal or abstract evaluates one’s perception of the product: How well does a website’s terms of service represent the relationship between a user and service provider? What does each party understand from it? What does each party have to gain or lose from it? Understanding the user’s perception of a design or product is inextricably linked to understanding the relationship formed between stakeholders. It doesn’t take technical knowledge to use a digital product but not fully understanding the mechanisms behind a product and relationships created or reinforced by a product makes it difficult to properly  and thoroughly evaluate decisions. The cloud is, obviously, not an airborne mass of condensed water molecules. If users, for example, think of the cloud of someone else’s computer or a distant remote server and not some floating omnipresent mass, how would their practices change? Would users be more careful about what they choose to leave on cloud storage? Would users evaluate the trade offs between convenience and security more? By understanding how consumers perceive the cloud, designers can better wrestle with the implications of designing “for the cloud.” </p>
<img src="https://d21ii91i3y6o6h.cloudfront.net/gallery_images/from_proof/3442/large/1418280711/die-cut-stickers.png">
<p>Visibility is not necessarily better than invisibility, and literal is not better than abstract by default. These binaries exist to simply assist in evaluating a design. Which end is preferred is up to the designer’s discretion. In the examples below, I presented a series of words related to technology to individuals and asked to place them on the map, based on their understanding of the word. Their explanations, shaped by their unique experiences and knowledge, shed light on how technology is perceived and present potential design interventions. </p>

<p>Surveillance</p>
<p>A describes surveillance as “murky.” A placed it towards invisible, as one can maybe see the camera and who is behind the camera is not always obvious. It is unclear what data is exactly being collected and how it is being used. The surveilled is only left with a sense of paranoia. The singular camera is the visible touchpoint for a greater social systems related to ownership and control, among others, that enable and support surveillance as a practice. 
B placed surveillance as invisible, but she noted a trend in surveillance becoming even more invisible. In a traditional sense, surveillance through a CCTV camera is quite literal and visible, but surveillance is now less about capturing one’s likeness on camera in a certain location. She described surveillance as “how accessible you are to whoever’s trying to find you.” Photo metadata, social media check ins, search engine histories and more can all be used to paint a fairly robust profile of an individual's identity, activities, and habits. However, as demonstrated by burglars or drone strikes, the accuracy of these profiles varies.   
Database is an installation that increases the visibility of surveillance by capturing the identity of passerbys, printing it, and then immediately shredding it, prompting individuals to question why their data is collected and what is done with it.</p>

<p>Machine learning</p>
<p>A is computer science major. She placed it towards “invisible,” as, in her opinion, machine learning is code. To her, code is essentially invisible to the end user; people just see the program they use. B is placed just above invisible because we often interact with products utilising machine learning, whereas C is invisible because it is not always obvious when we are interacting with the products of machine learning. </p>
<p>A felt that machine learning was “abstract” because at the end of the day, “literally it’s an algorithm.” She also noted that machine learning is a bit of a buzzword, and acts as a keyword or stand in for various technologies. B and C felt that it was quite literal; the machine is learning. This discrepancy is rather telling; “algorithms” and “learning” have very different meanings. “Algorithms” are a set of rules , while “learning” suggests growth and change. By focusing on the machine “learning,” the individual or team that wrote the algorithm has essentially been rendered invisible and is abstracted by the machine; the human element is erased. Are we placing excessive trust in machines as a result? We can select which datasets to feed an algorithm, what parameters to train it on, but how the algorithm made its  judgement calls is less clear. Many aspects of our lives, from things as seemingly trivial as the order of content on social media newsfeeds to something as important as an loan application, are decided by machine learning outcomes. When election outcomes can be swayed by machine learning, shouldn’t the general public be aware of how their realities are being constructed and curated by such technologies? There is plenty of technical  literature on evaluating machine learning algorithms, but how can the general public begin to understand how machine learning decisions are made? If the focus is placed on “learning”, we could use Bloom’s Taxonomy as a starting point. It might not seem particularly appropriate to use a human model to evaluate machine behavior, but machine learning is often performing tasks previously completed by humans. Machine learning fulfills some aspects of Bloom’s Taxonomy but outright fails others. By focusing on improving and emphasizing these aspects, designers can potentially bring more transparency to machine learning, partially by abstracting it into a more human model. Metaphors are necessary to aid in explaining and understanding, but we need to consider what these reductions inadvertently assume or omit. </p>

<p>David Cole notes that interface design has more or less reached maturity. Interfaces for various products begin to resemble one another; after all, utilising common UI patterns does allow for greater ease of use. However if design is going to truly be as impactful as it claims to be, designers need to be designing for transparency in relationships. Conclusion should touch upon “transparency” and “seamfullness” If design is to be focused on relationships, it is necessary to evaluate the transparency of these ties. </p>